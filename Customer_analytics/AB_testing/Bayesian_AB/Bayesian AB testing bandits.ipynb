{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/beyond-a-b-testing-multi-armed-bandit-experiments-1493f709f804\n",
    "https://www.kaggle.com/cstorm3000/multi-armed-bandits-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "#plots\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "from mizani import *\n",
    "\n",
    "#stats\n",
    "import scipy as sp\n",
    "import statsmodels as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_day</th>\n",
       "      <th>click_a</th>\n",
       "      <th>click_b</th>\n",
       "      <th>conv_a</th>\n",
       "      <th>conv_b</th>\n",
       "      <th>cumu_click_a</th>\n",
       "      <th>cumu_click_b</th>\n",
       "      <th>cumu_conv_a</th>\n",
       "      <th>cumu_conv_b</th>\n",
       "      <th>cumu_rate_a</th>\n",
       "      <th>cumu_rate_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>80</td>\n",
       "      <td>129</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2044</td>\n",
       "      <td>1866</td>\n",
       "      <td>192</td>\n",
       "      <td>188</td>\n",
       "      <td>0.093933</td>\n",
       "      <td>0.100750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2144</td>\n",
       "      <td>1967</td>\n",
       "      <td>201</td>\n",
       "      <td>198</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.100661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>135</td>\n",
       "      <td>77</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2279</td>\n",
       "      <td>2044</td>\n",
       "      <td>214</td>\n",
       "      <td>205</td>\n",
       "      <td>0.093901</td>\n",
       "      <td>0.100294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>112</td>\n",
       "      <td>93</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2391</td>\n",
       "      <td>2137</td>\n",
       "      <td>225</td>\n",
       "      <td>215</td>\n",
       "      <td>0.094103</td>\n",
       "      <td>0.100608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>97</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2488</td>\n",
       "      <td>2209</td>\n",
       "      <td>234</td>\n",
       "      <td>222</td>\n",
       "      <td>0.094051</td>\n",
       "      <td>0.100498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    click_day  click_a  click_b  conv_a  conv_b  cumu_click_a  cumu_click_b  \\\n",
       "19         19       80      129       8      14          2044          1866   \n",
       "20         20      100      101       9      10          2144          1967   \n",
       "21         21      135       77      13       7          2279          2044   \n",
       "22         22      112       93      11      10          2391          2137   \n",
       "23         23       97       72       9       7          2488          2209   \n",
       "\n",
       "    cumu_conv_a  cumu_conv_b  cumu_rate_a  cumu_rate_b  \n",
       "19          192          188     0.093933     0.100750  \n",
       "20          201          198     0.093750     0.100661  \n",
       "21          214          205     0.093901     0.100294  \n",
       "22          225          215     0.094103     0.100608  \n",
       "23          234          222     0.094051     0.100498  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_campaigns(p1,p2,nb_days,scaler,seed):\n",
    "    #generate fake data\n",
    "    np.random.seed(seed)\n",
    "    ns = np.random.triangular(50,100,150,size=nb_days*2).astype(int)\n",
    "    np.random.seed(seed)\n",
    "    es = np.random.randn(nb_days*2) / scaler\n",
    "\n",
    "    n1 = ns[:nb_days]\n",
    "    c1 = ((p1 + es[:nb_days]) * n1).astype(int)\n",
    "    n2 = ns[nb_days:]\n",
    "    c2 = ((p2 + es[nb_days:]) * n2).astype(int)\n",
    "    conv_days = pd.DataFrame({'click_day':range(nb_days),'click_a':n1,'conv_a':c1,'click_b':n2,'conv_b':c2})\n",
    "\n",
    "    conv_days =  conv_days[['click_day','click_a','click_b','conv_a','conv_b']]\n",
    "    conv_days['cumu_click_a'] = conv_days.click_a.cumsum()\n",
    "    conv_days['cumu_click_b'] = conv_days.click_b.cumsum()\n",
    "    conv_days['cumu_conv_a'] = conv_days.conv_a.cumsum()\n",
    "    conv_days['cumu_conv_b'] = conv_days.conv_b.cumsum()\n",
    "    conv_days['cumu_rate_a'] = conv_days.cumu_conv_a / conv_days.cumu_click_a\n",
    "    conv_days['cumu_rate_b'] = conv_days.cumu_conv_b / conv_days.cumu_click_b\n",
    "    return conv_days\n",
    "\n",
    "conv_days = gen_campaigns(p1 = 0.10,\n",
    "                          p2 = 0.105,\n",
    "                          nb_days = 24,\n",
    "                          scaler=300,\n",
    "                          seed = 1412) #god-mode \n",
    "conv_days.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arm(object):\n",
    "    \"\"\"\n",
    "    Each arm's true click through rate is \n",
    "    modeled by a beta distribution.\n",
    "    \"\"\"\n",
    "    def __init__(self, idx, a=1, b=1):\n",
    "        \"\"\"\n",
    "        Init with uniform prior.\n",
    "        \"\"\"\n",
    "        self.idx = idx\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def record_success(self):\n",
    "        self.a += 1\n",
    "        \n",
    "    def record_failure(self):\n",
    "        self.b += 1\n",
    "        \n",
    "    def draw_ctr(self):\n",
    "        return np.random.beta(self.a, self.b, 1)[0]\n",
    "    \n",
    "    def mean(self):\n",
    "        return self.a / (self.a + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_simulation(arms, draw=100):\n",
    "    \"\"\"\n",
    "    Monte Carlo simulation of thetas. Each arm's click through\n",
    "    rate follows a beta distribution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arms list[Arm]: list of Arm objects.\n",
    "    draw int: number of draws in Monte Carlo simulation.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mc np.matrix: Monte Carlo matrix of dimension (draw, n_arms).\n",
    "    p_winner list[float]: probability of each arm being the winner.\n",
    "    \"\"\"\n",
    "    # Monte Carlo sampling\n",
    "    alphas = [arm.a for arm in arms]\n",
    "    betas = [arm.b for arm in arms]\n",
    "    mc = np.matrix(np.random.beta(alphas, betas, size=[draw, len(arms)]))\n",
    "    \n",
    "    # count frequency of each arm being winner \n",
    "    counts = [0 for _ in arms]\n",
    "    winner_idxs = np.asarray(mc.argmax(axis=1)).reshape(draw,)\n",
    "    for idx in winner_idxs:\n",
    "        counts[idx] += 1\n",
    "    \n",
    "    # divide by draw to approximate probability distribution\n",
    "    p_winner = [count / draw for count in counts]\n",
    "    return mc, p_winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thompson_sampling(arms):\n",
    "    \"\"\"\n",
    "    Stochastic sampling: take one draw for each arm\n",
    "    divert traffic to best draw.\n",
    "    \n",
    "    @param arms list[Arm]: list of Arm objects\n",
    "    @return idx int: index of winning arm from sample\n",
    "    \"\"\"\n",
    "    sample_p = [arm.draw_ctr() for arm in arms]\n",
    "    idx = np.argmax(sample_p)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_terminate(p_winner, est_ctrs, mc, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Decide whether experiument should terminate. When value remaining in\n",
    "    experiment is less than 1% of the winning arm's click through rate.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p_winner list[float]: probability of each arm being the winner.\n",
    "    est_ctrs list[float]: estimated click through rates.\n",
    "    mc np.matrix: Monte Carlo matrix of dimension (draw, n_arms).\n",
    "    alpha: controlling for type I error\n",
    "    \n",
    "    @returns bool: True if experiment should terminate.\n",
    "    \"\"\"\n",
    "    winner_idx = np.argmax(p_winner)\n",
    "    values_remaining = (mc.max(axis=1) - mc[:, winner_idx]) / mc[:, winner_idx]\n",
    "    pctile = np.percentile(values_remaining, q=100 * (1 - alpha))\n",
    "    return pctile < 0.01 * est_ctrs[winner_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_arm_bandit(ctrs, alpha=0.05, burn_in=1000, max_iter=100000, draw=100, silent=False):\n",
    "    \"\"\"\n",
    "    Perform stochastic k-arm bandit test. Experiment is terminated when\n",
    "    value remained in experiment drops below certain threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ctrs list[float]: true click through rates for each arms.\n",
    "    alpha float: terminate experiment when the (1 - alpha)th percentile\n",
    "        of the remaining value is less than 1% of the winner's click through rate.\n",
    "    burn_in int: minimum number of iterations.\n",
    "    max_iter int: maxinum number of iterations.\n",
    "    draw int: number of rows in Monte Carlo simulation.\n",
    "    silent bool: print status at the end of experiment.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    idx int: winner's index.\n",
    "    est_ctrs list[float]: estimated click through rates.\n",
    "    history_p list[list[float]]: storing est_ctrs and p_winner.\n",
    "    traffic list[int]: number of traffic in each arm.\n",
    "    \"\"\"\n",
    "    n_arms = len(ctrs)\n",
    "    arms = [Arm(idx=i) for i in range(n_arms)]\n",
    "    history_p = [[] for _ in range(n_arms)]\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        idx = thompson_sampling(arms)\n",
    "        arm, ctr = arms[idx], ctrs[idx]\n",
    "\n",
    "        # update arm's beta parameters\n",
    "        if np.random.rand() < ctr:\n",
    "            arm.record_success()\n",
    "        else:\n",
    "            arm.record_failure()\n",
    "\n",
    "        # record current estimates of each arm being winner\n",
    "        mc, p_winner = monte_carlo_simulation(arms, draw)\n",
    "        for j, p in enumerate(p_winner):\n",
    "            history_p[j].append(p)\n",
    "            \n",
    "        # record current estimates of each arm's ctr\n",
    "        est_ctrs = [arm.mean() for arm in arms]\n",
    "        \n",
    "        # terminate when value remaining is negligible\n",
    "        if i >= burn_in and should_terminate(p_winner, est_ctrs, mc, alpha):\n",
    "            if not silent: print(\"Terminated at iteration %i\"%(i + 1))\n",
    "            break\n",
    "\n",
    "    traffic = [arm.a + arm.b - 2 for arm in arms]\n",
    "    return idx, est_ctrs, history_p, traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_winner_idx: 1 [0.04, 0.048, 0.03, 0.037, 0.044]\n",
      "Terminated at iteration 14385\n"
     ]
    }
   ],
   "source": [
    "seed = 11\n",
    "np.random.seed(seed)\n",
    "\n",
    "ctrs = [0.04, 0.048, 0.03, 0.037, 0.044]\n",
    "true_winner_idx = np.argmax(ctrs)\n",
    "print(\"true_winner_idx:\", true_winner_idx, ctrs)\n",
    "\n",
    "(winner_idx, est_ctrs, history_p, traffic) = k_arm_bandit(ctrs, alpha=0.05, burn_in=1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b5ee1bd1b824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m plot_history(ctrs, est_ctrs, history_p, \n\u001b[0m\u001b[0;32m      2\u001b[0m              title=\"K-armed Bandit Algorithm (terminated in %i iterations)\"%sum(traffic), rolling=100)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(ctrs, est_ctrs, history_p, \n",
    "             title=\"K-armed Bandit Algorithm (terminated in %i iterations)\"%sum(traffic), rolling=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "#plots\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "\n",
    "#stats\n",
    "import scipy as sp\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arm:\n",
    "    def __init__(self, true_p):\n",
    "        self.true_p = true_p\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.impressions = 0\n",
    "        self.actions = 0\n",
    "    def get_state(self):\n",
    "        return self.impressions,self.actions\n",
    "    def get_rate(self):\n",
    "        return self.actions / self.impressions if self.impressions >0 else 0.\n",
    "    def pull(self):\n",
    "        self.impressions+=1\n",
    "        res = 1 if np.random.random() < self.true_p else 0\n",
    "        self.actions+=res\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Arm(0.1)\n",
    "for i in range(100): a.pull()\n",
    "a.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusketeerEnv:\n",
    "    def __init__(self, true_ps, avg_impressions):\n",
    "        self.true_ps = true_ps\n",
    "        self.avg_impressions = avg_impressions\n",
    "        self.nb_arms = len(true_ps)\n",
    "        self.vr_agent = BanditAgent()\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.t = -1\n",
    "        self.ds=[]\n",
    "        self.arms = [Arm(p) for p in self.true_ps]\n",
    "        return self.get_state()\n",
    "    def get_state(self):\n",
    "        return [self.arms[i].get_state() for i in range(self.nb_arms)]\n",
    "    def get_rates(self):\n",
    "        return [self.arms[i].get_rate() for i in range(self.nb_arms)]\n",
    "    def get_impressions(self):\n",
    "        return int(np.random.triangular(self.avg_impressions/2,\n",
    "                                    self.avg_impressions,\n",
    "                                    self.avg_impressions*1.5))\n",
    "    def step(self, ps):\n",
    "        self.t+=1\n",
    "        impressions = self.get_impressions()\n",
    "        for i in np.random.choice(a=self.nb_arms,size=impressions,p=ps):\n",
    "            self.arms[i].pull()\n",
    "        self.record()\n",
    "        return self.get_state()\n",
    "    #use agent to calculate value remaining\n",
    "    def value_remaining(self,n=1000,q=95):\n",
    "        state = self.get_state()\n",
    "        best_idx = np.argmax(self.vr_agent.thompson_stochastic(state))\n",
    "        l=[]\n",
    "        for i in range(n): l.append(self.vr_agent.thompson_one(state)[None,:])\n",
    "        l = np.concatenate(l,0)\n",
    "        l_max = l.max(1)\n",
    "        l_best = l[:,best_idx]\n",
    "        vs = (l_max - l_best)/l_best\n",
    "        return np.percentile(vs,q)\n",
    "    def record(self):\n",
    "        d = {'t':self.t,'max_rate':0,'opt_impressions':0}\n",
    "        for i in range(self.nb_arms):\n",
    "            d[f'impressions_{i}'],d[f'actions_{i}'] = self.arms[i].get_state()\n",
    "            d[f'rate_{i}'] = self.arms[i].get_rate()\n",
    "            if d[f'rate_{i}'] > d['max_rate']: \n",
    "                d['max_rate'] = d[f'rate_{i}']\n",
    "                d['opt_impressions'] = d[f'impressions_{i}']\n",
    "        d['total_impressions'] = sum([self.arms[i].impressions for i in range(self.nb_arms)])\n",
    "        d['opt_impressions_rate'] = d['opt_impressions'] / d['total_impressions']\n",
    "        d['total_actions'] = sum([self.arms[i].actions for i in range(self.nb_arms)])\n",
    "        d['total_rate'] = d['total_actions'] / d['total_impressions']\n",
    "        d['regret_rate'] = d['max_rate'] - d['total_rate']\n",
    "        d['regret'] = d['regret_rate'] * d['total_impressions']\n",
    "        d['value_remaining'] = self.value_remaining()\n",
    "        self.ds.append(d)\n",
    "    def show_df(self):\n",
    "        df = pd.DataFrame(self.ds)\n",
    "        cols = ['t'] + [f'rate_{i}' for i in range(self.nb_arms)]+ \\\n",
    "               [f'impressions_{i}' for i in range(self.nb_arms)]+ \\\n",
    "               [f'actions_{i}' for i in range(self.nb_arms)]+ \\\n",
    "               ['total_impressions','total_actions','total_rate']+ \\\n",
    "               ['opt_impressions','opt_impressions_rate']+ \\\n",
    "               ['regret_rate','regret','value_remaining']\n",
    "        df = df[cols]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    #thompsons\n",
    "    def thompson_one(self,state):\n",
    "        res = [np.random.beta(i[1]+1,i[0]-i[1]+1) for i in state]\n",
    "        res = np.array(res)\n",
    "        return res\n",
    "    def thompson_stochastic(self,state,n=1000):\n",
    "        l = []\n",
    "        for i in range(n): l.append(self.thompson_one(state)[None,:])\n",
    "        l = np.concatenate(l,0)\n",
    "        is_max = l.max(1)[:,None] == l\n",
    "        return is_max.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10044147304557087, 0.12003000750187547, 0.12968927021143883]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = MusketeerEnv(true_ps = [0.1,0.12,0.13], avg_impressions=400)\n",
    "for i in range(1000):\n",
    "    env.step([0.6,0.2,0.2])\n",
    "env.get_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>rate_0</th>\n",
       "      <th>rate_1</th>\n",
       "      <th>rate_2</th>\n",
       "      <th>impressions_0</th>\n",
       "      <th>impressions_1</th>\n",
       "      <th>impressions_2</th>\n",
       "      <th>actions_0</th>\n",
       "      <th>actions_1</th>\n",
       "      <th>actions_2</th>\n",
       "      <th>total_impressions</th>\n",
       "      <th>total_actions</th>\n",
       "      <th>total_rate</th>\n",
       "      <th>opt_impressions</th>\n",
       "      <th>opt_impressions_rate</th>\n",
       "      <th>regret_rate</th>\n",
       "      <th>regret</th>\n",
       "      <th>value_remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>256</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>409</td>\n",
       "      <td>44</td>\n",
       "      <td>0.107579</td>\n",
       "      <td>67</td>\n",
       "      <td>0.163814</td>\n",
       "      <td>0.041674</td>\n",
       "      <td>17.044776</td>\n",
       "      <td>0.588573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>468</td>\n",
       "      <td>161</td>\n",
       "      <td>146</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>775</td>\n",
       "      <td>86</td>\n",
       "      <td>0.110968</td>\n",
       "      <td>146</td>\n",
       "      <td>0.188387</td>\n",
       "      <td>0.026019</td>\n",
       "      <td>20.164384</td>\n",
       "      <td>0.517409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.088456</td>\n",
       "      <td>0.111607</td>\n",
       "      <td>0.140187</td>\n",
       "      <td>667</td>\n",
       "      <td>224</td>\n",
       "      <td>214</td>\n",
       "      <td>59</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>1105</td>\n",
       "      <td>114</td>\n",
       "      <td>0.103167</td>\n",
       "      <td>214</td>\n",
       "      <td>0.193665</td>\n",
       "      <td>0.037019</td>\n",
       "      <td>40.906542</td>\n",
       "      <td>0.212233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.089087</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.128378</td>\n",
       "      <td>898</td>\n",
       "      <td>289</td>\n",
       "      <td>296</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>1483</td>\n",
       "      <td>152</td>\n",
       "      <td>0.102495</td>\n",
       "      <td>296</td>\n",
       "      <td>0.199595</td>\n",
       "      <td>0.025883</td>\n",
       "      <td>38.385135</td>\n",
       "      <td>0.290442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.088768</td>\n",
       "      <td>0.107955</td>\n",
       "      <td>0.133880</td>\n",
       "      <td>1104</td>\n",
       "      <td>352</td>\n",
       "      <td>366</td>\n",
       "      <td>98</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>1822</td>\n",
       "      <td>185</td>\n",
       "      <td>0.101537</td>\n",
       "      <td>366</td>\n",
       "      <td>0.200878</td>\n",
       "      <td>0.032343</td>\n",
       "      <td>58.928962</td>\n",
       "      <td>0.111080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t    rate_0    rate_1    rate_2  impressions_0  impressions_1  \\\n",
       "0  0  0.089844  0.127907  0.149254            256             86   \n",
       "1  1  0.096154  0.130435  0.136986            468            161   \n",
       "2  2  0.088456  0.111607  0.140187            667            224   \n",
       "3  3  0.089087  0.117647  0.128378            898            289   \n",
       "4  4  0.088768  0.107955  0.133880           1104            352   \n",
       "\n",
       "   impressions_2  actions_0  actions_1  actions_2  total_impressions  \\\n",
       "0             67         23         11         10                409   \n",
       "1            146         45         21         20                775   \n",
       "2            214         59         25         30               1105   \n",
       "3            296         80         34         38               1483   \n",
       "4            366         98         38         49               1822   \n",
       "\n",
       "   total_actions  total_rate  opt_impressions  opt_impressions_rate  \\\n",
       "0             44    0.107579               67              0.163814   \n",
       "1             86    0.110968              146              0.188387   \n",
       "2            114    0.103167              214              0.193665   \n",
       "3            152    0.102495              296              0.199595   \n",
       "4            185    0.101537              366              0.200878   \n",
       "\n",
       "   regret_rate     regret  value_remaining  \n",
       "0     0.041674  17.044776         0.588573  \n",
       "1     0.026019  20.164384         0.517409  \n",
       "2     0.037019  40.906542         0.212233  \n",
       "3     0.025883  38.385135         0.290442  \n",
       "4     0.032343  58.928962         0.111080  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.show_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    #baselines\n",
    "    def equal_weights(self,state):\n",
    "        res = np.array([1/len(state) for i in range(len(state))])\n",
    "        return res\n",
    "    def randomize(self,state):\n",
    "        res = np.random.rand(len(state))\n",
    "        res /= res.sum()\n",
    "        return res\n",
    "    \n",
    "    #stochastic policies\n",
    "    def eps_greedy(self, state, t, start_eps=0.3, end_eps=0.01, gamma=0.99):\n",
    "        eps = max(end_eps,start_eps * gamma**t)\n",
    "        res = np.array([eps/len(state) for i in range(len(state))])\n",
    "        best_idx = np.argmax([i[1]/i[0] for i in state]) if t > 0 else np.random.choice(range(len(state)))\n",
    "        res[best_idx] += 1-eps\n",
    "        return res\n",
    "    def softmax(self, state, t, start_tau=1e-1, end_tau=1e-4, gamma=0.9):\n",
    "        tau = max(end_tau,start_tau*gamma**t)\n",
    "        sum_exp = sum([np.exp(i[1]/(i[0]+1e6)/tau) for i in state])\n",
    "        res = np.array([np.exp(i[1]/(i[0]+1e6)/tau) / sum_exp for i in state])\n",
    "        return res\n",
    "    \n",
    "    #deterministic policies\n",
    "    def ucb(self, state, t):\n",
    "        for i in state:\n",
    "            if i[0]==0:\n",
    "                return self.equal_weights(state)\n",
    "        res = [(i[1]/i[0] + np.sqrt(2*np.log(t+1)/i[0])) for i in state]\n",
    "        res = np.array(res)\n",
    "        res_d = np.zeros(len(state))\n",
    "        res_d[np.argmax(res)] = 1\n",
    "        return res_d\n",
    "    def thompson_deterministic(self, state):\n",
    "        res = [np.random.beta(i[1]+1,i[0]-i[1]+1) for i in state]\n",
    "        res = np.array(res)\n",
    "        res_d = np.zeros(len(state))\n",
    "        res_d[np.argmax(res)] = 1\n",
    "        return res_d\n",
    "    \n",
    "    #thompsons\n",
    "    def thompson_one(self,state):\n",
    "        res = [np.random.beta(i[1]+1,i[0]-i[1]+1) for i in state]\n",
    "        res = np.array(res)\n",
    "        return res\n",
    "    def thompson_stochastic(self,state,n=1000):\n",
    "        l = []\n",
    "        for i in range(n): l.append(self.thompson_one(state)[None,:])\n",
    "        l = np.concatenate(l,0)\n",
    "        is_max = l.max(1)[:,None] == l\n",
    "        return is_max.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.33333333, 0.33333333, 0.33333333]),\n",
       " array([0.60072498, 0.13653053, 0.26274449]),\n",
       " array([0.08261686, 0.83476628, 0.08261686]),\n",
       " array([0.33261137, 0.33371931, 0.33366932]),\n",
       " array([0.002, 0.678, 0.32 ]),\n",
       " array([0., 1., 0.]),\n",
       " array([0., 0., 1.]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = MusketeerEnv(true_ps = [0.12,0.13,0.14], avg_impressions=400)\n",
    "a = BanditAgent()\n",
    "for i in range(20):\n",
    "    p = a.equal_weights(env.get_state())\n",
    "    env.step(p)\n",
    "    t=i\n",
    "a.equal_weights(env.get_state()), a.randomize(env.get_state()), a.eps_greedy(env.get_state(),t),\\\n",
    "a.softmax(env.get_state(),t), a.thompson_stochastic(env.get_state()), \\\n",
    "a.ucb(env.get_state(),t), a.thompson_deterministic(env.get_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = [MusketeerEnv(true_ps = [0.12,0.13,0.14], avg_impressions=400) for i in range(7)]\n",
    "a = BanditAgent()\n",
    "for t in range(200):\n",
    "    states = [env.get_state() for env in envs]\n",
    "    actions = [a.equal_weights(states[0]), a.randomize(states[1]),\n",
    "               a.eps_greedy(states[2],t), a.softmax(states[3],t),\n",
    "               a.thompson_stochastic(states[4]),\n",
    "               a.ucb(states[5],t), a.thompson_deterministic(states[6])]\n",
    "    for i in range(7): envs[i].step(actions[i])\n",
    "dfs = [env.show_df() for env in envs]\n",
    "policies = ['equal_weights','randomize','eps_greedy','softmax','thompson_stochastic',\n",
    "            'ucb','thompson_deterministic']\n",
    "for i in range(7): dfs[i]['policy'] = policies[i]\n",
    "df = pd.concat(dfs)[['policy','t','opt_impressions_rate','regret_rate','regret','value_remaining']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy</th>\n",
       "      <th>t</th>\n",
       "      <th>opt_impressions_rate</th>\n",
       "      <th>regret_rate</th>\n",
       "      <th>regret</th>\n",
       "      <th>value_remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>thompson_deterministic</td>\n",
       "      <td>195</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>113.110267</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>thompson_deterministic</td>\n",
       "      <td>196</td>\n",
       "      <td>0.854335</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>112.648052</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>thompson_deterministic</td>\n",
       "      <td>197</td>\n",
       "      <td>0.854806</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>112.851912</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>thompson_deterministic</td>\n",
       "      <td>198</td>\n",
       "      <td>0.855497</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>112.355267</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>thompson_deterministic</td>\n",
       "      <td>199</td>\n",
       "      <td>0.856088</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>112.913086</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     policy    t  opt_impressions_rate  regret_rate  \\\n",
       "195  thompson_deterministic  195              0.853583     0.001435   \n",
       "196  thompson_deterministic  196              0.854335     0.001422   \n",
       "197  thompson_deterministic  197              0.854806     0.001420   \n",
       "198  thompson_deterministic  198              0.855497     0.001407   \n",
       "199  thompson_deterministic  199              0.856088     0.001408   \n",
       "\n",
       "         regret  value_remaining  \n",
       "195  113.110267              0.0  \n",
       "196  112.648052              0.0  \n",
       "197  112.851912              0.0  \n",
       "198  112.355267              0.0  \n",
       "199  112.913086              0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy</th>\n",
       "      <th>t</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>thompson_deterministic</td>\n",
       "      <td>195</td>\n",
       "      <td>value_remaining</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>thompson_deterministic</td>\n",
       "      <td>196</td>\n",
       "      <td>value_remaining</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5597</th>\n",
       "      <td>thompson_deterministic</td>\n",
       "      <td>197</td>\n",
       "      <td>value_remaining</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>thompson_deterministic</td>\n",
       "      <td>198</td>\n",
       "      <td>value_remaining</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>thompson_deterministic</td>\n",
       "      <td>199</td>\n",
       "      <td>value_remaining</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      policy    t         variable  value\n",
       "5595  thompson_deterministic  195  value_remaining    0.0\n",
       "5596  thompson_deterministic  196  value_remaining    0.0\n",
       "5597  thompson_deterministic  197  value_remaining    0.0\n",
       "5598  thompson_deterministic  198  value_remaining    0.0\n",
       "5599  thompson_deterministic  199  value_remaining    0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m = df.melt(id_vars=['policy','t'])\n",
    "df_m.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-b53a58788c9a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-b53a58788c9a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    group='policy')) +\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "group='policy')) +\n",
    "    geom_line() + theme_minimal() + facet_wrap('~variable',scales='free_y'))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
